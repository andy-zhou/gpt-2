{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results: With all the following improvements\n",
    "\n",
    "- BFloat16 mixed precision training\n",
    "- `torch.compile()`\n",
    "- Flash Attention 2\n",
    "- Vocabulary rounded to the nearest multiple of 64\n",
    "\n",
    "I see a ~9.3% improve in tokens throughput.\n",
    "\n",
    "Notes:\n",
    "- I think the BFloat16 option clobbers the TFloat32 option, since `torch.amp` will optimize matrix multiplations to BFloat16, overriding the default of `torch.set_float32_matmul_precision('high')`. For more information, see [here](https://pytorch.org/docs/stable/amp.html#cuda-op-specific-behavior).\n",
    "- `F.scaled_dot_product_attention` does not necessarily use a Flash Attention kernel. Previously I had bug where I provided an attention-mask to the function, which caused it to fall back to the \"Memory-Efficient Attention\" kernel. I haven't investigated this further, but it's possible that other configurations, like the use of float32, could also cause a similar behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src import data, modules, pipeline, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing Stories: 100%|████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1402.65 stories/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_heads = 12\n",
    "embed_dim = 768\n",
    "context_len = 1024\n",
    "vocab_size = 50257\n",
    "device = \"cuda\"\n",
    "\n",
    "dataset = data.TinyStoriesDataset(1024, num_stories=500)\n",
    "train_ds = Subset(dataset, list(range(batch_size)))\n",
    "eval_ds = Subset(dataset, list(range(batch_size, 2 * batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7fd94ee8364d6bb906dc628aef31ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 11.53 | Avg Forward Time: 589.73 | Avg Backward Time: 830.79\n",
      "fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.283 | Tokens/ms: 13.68 | Avg Forward Time: 456.10 | Avg Backward Time: 741.99\n",
      "fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.975 | Eval Loss: 6.102 | Tokens/ms: 13.60 | Avg Forward Time: 458.27 | Avg Backward Time: 746.44\n",
      "fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.741 | Eval Loss: 5.743 | Tokens/ms: 13.54 | Avg Forward Time: 460.97 | Avg Backward Time: 749.33\n",
      "fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.890 | Eval Loss: 5.663 | Tokens/ms: 13.49 | Avg Forward Time: 462.36 | Avg Backward Time: 751.97\n",
      "fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.081 | Eval Loss: 5.848 | Tokens/ms: 13.46 | Avg Forward Time: 463.21 | Avg Backward Time: 754.43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8debb9a9d2a4454bb10f87ab5aa4e190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 29.52 | Avg Forward Time: 280.80 | Avg Backward Time: 274.21\n",
      "tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.284 | Tokens/ms: 31.62 | Avg Forward Time: 245.79 | Avg Backward Time: 272.29\n",
      "tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.975 | Eval Loss: 6.103 | Tokens/ms: 31.57 | Avg Forward Time: 246.35 | Avg Backward Time: 272.66\n",
      "tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.741 | Eval Loss: 5.743 | Tokens/ms: 31.56 | Avg Forward Time: 246.42 | Avg Backward Time: 272.77\n",
      "tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.895 | Eval Loss: 5.666 | Tokens/ms: 31.54 | Avg Forward Time: 246.42 | Avg Backward Time: 273.05\n",
      "tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.090 | Eval Loss: 5.841 | Tokens/ms: 31.55 | Avg Forward Time: 246.47 | Avg Backward Time: 272.89\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520f81ffd0a14e2e896c109a5a1bbb3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 27.90 | Avg Forward Time: 331.45 | Avg Backward Time: 255.75\n",
      "bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.282 | Tokens/ms: 33.20 | Avg Forward Time: 239.25 | Avg Backward Time: 254.25\n",
      "bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.975 | Eval Loss: 6.090 | Tokens/ms: 33.19 | Avg Forward Time: 239.41 | Avg Backward Time: 254.29\n",
      "bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.722 | Eval Loss: 5.746 | Tokens/ms: 33.16 | Avg Forward Time: 239.64 | Avg Backward Time: 254.42\n",
      "bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.878 | Eval Loss: 5.661 | Tokens/ms: 33.17 | Avg Forward Time: 239.58 | Avg Backward Time: 254.33\n",
      "bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.074 | Eval Loss: 5.848 | Tokens/ms: 33.15 | Avg Forward Time: 239.87 | Avg Backward Time: 254.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335b7b313fad4697bfdbd0a451bcb982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 33.16 | Avg Forward Time: 238.54 | Avg Backward Time: 255.55\n",
      "tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.282 | Tokens/ms: 33.20 | Avg Forward Time: 239.29 | Avg Backward Time: 254.24\n",
      "tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.975 | Eval Loss: 6.090 | Tokens/ms: 33.17 | Avg Forward Time: 239.57 | Avg Backward Time: 254.41\n",
      "tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.722 | Eval Loss: 5.746 | Tokens/ms: 33.14 | Avg Forward Time: 239.85 | Avg Backward Time: 254.49\n",
      "tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.878 | Eval Loss: 5.661 | Tokens/ms: 33.09 | Avg Forward Time: 240.48 | Avg Backward Time: 254.68\n",
      "tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.074 | Eval Loss: 5.848 | Tokens/ms: 33.09 | Avg Forward Time: 240.40 | Avg Backward Time: 254.73\n"
     ]
    }
   ],
   "source": [
    "# Overfit on a single batch\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    model = modules.GPT2(vocab_size, embed_dim, context_len, num_heads)\n",
    "    model.to(device)\n",
    "    labels = []\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 0:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d056221893f4acfb5a4e593d5d294b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 16.75 | Avg Forward Time: 374.49 | Avg Backward Time: 603.39\n",
      "flash_attn, fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.283 | Tokens/ms: 16.76 | Avg Forward Time: 376.10 | Avg Backward Time: 601.50\n",
      "flash_attn, fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.975 | Eval Loss: 6.102 | Tokens/ms: 16.70 | Avg Forward Time: 376.96 | Avg Backward Time: 604.17\n",
      "flash_attn, fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.741 | Eval Loss: 5.743 | Tokens/ms: 16.64 | Avg Forward Time: 378.40 | Avg Backward Time: 606.06\n",
      "flash_attn, fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.890 | Eval Loss: 5.663 | Tokens/ms: 16.58 | Avg Forward Time: 379.65 | Avg Backward Time: 608.60\n",
      "flash_attn, fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.081 | Eval Loss: 5.848 | Tokens/ms: 16.58 | Avg Forward Time: 379.83 | Avg Backward Time: 608.62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108390508503415e9be87a1337c9e007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 39.12 | Avg Forward Time: 197.02 | Avg Backward Time: 221.84\n",
      "flash_attn, tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.706 | Eval Loss: 7.284 | Tokens/ms: 38.88 | Avg Forward Time: 201.00 | Avg Backward Time: 220.36\n",
      "flash_attn, tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.975 | Eval Loss: 6.103 | Tokens/ms: 38.83 | Avg Forward Time: 201.26 | Avg Backward Time: 220.72\n",
      "flash_attn, tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.741 | Eval Loss: 5.743 | Tokens/ms: 38.84 | Avg Forward Time: 200.92 | Avg Backward Time: 220.91\n",
      "flash_attn, tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.895 | Eval Loss: 5.667 | Tokens/ms: 38.87 | Avg Forward Time: 200.78 | Avg Backward Time: 220.70\n",
      "flash_attn, tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.090 | Eval Loss: 5.841 | Tokens/ms: 38.86 | Avg Forward Time: 200.75 | Avg Backward Time: 220.83\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4df65c02f974a108b2d7c7d6d4a9eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.007 | Eval Loss: 9.714 | Tokens/ms: 49.24 | Avg Forward Time: 168.74 | Avg Backward Time: 163.97\n",
      "flash_attn, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.704 | Eval Loss: 7.282 | Tokens/ms: 49.02 | Avg Forward Time: 171.63 | Avg Backward Time: 162.57\n",
      "flash_attn, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.975 | Eval Loss: 6.086 | Tokens/ms: 48.98 | Avg Forward Time: 171.83 | Avg Backward Time: 162.65\n",
      "flash_attn, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.717 | Eval Loss: 5.747 | Tokens/ms: 49.00 | Avg Forward Time: 171.82 | Avg Backward Time: 162.54\n",
      "flash_attn, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.871 | Eval Loss: 5.653 | Tokens/ms: 49.01 | Avg Forward Time: 171.81 | Avg Backward Time: 162.50\n",
      "flash_attn, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.067 | Eval Loss: 5.851 | Tokens/ms: 48.97 | Avg Forward Time: 171.98 | Avg Backward Time: 162.57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc23b1eddd0c476399012aebe253ac11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.007 | Eval Loss: 9.714 | Tokens/ms: 49.21 | Avg Forward Time: 169.07 | Avg Backward Time: 163.84\n",
      "flash_attn, tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.282 | Tokens/ms: 49.01 | Avg Forward Time: 171.86 | Avg Backward Time: 162.45\n",
      "flash_attn, tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.973 | Eval Loss: 6.068 | Tokens/ms: 48.97 | Avg Forward Time: 171.98 | Avg Backward Time: 162.59\n",
      "flash_attn, tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.682 | Eval Loss: 5.758 | Tokens/ms: 48.95 | Avg Forward Time: 172.10 | Avg Backward Time: 162.58\n",
      "flash_attn, tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.822 | Eval Loss: 5.660 | Tokens/ms: 48.98 | Avg Forward Time: 171.90 | Avg Backward Time: 162.61\n",
      "flash_attn, tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 2.993 | Eval Loss: 5.859 | Tokens/ms: 48.97 | Avg Forward Time: 171.97 | Avg Backward Time: 162.60\n"
     ]
    }
   ],
   "source": [
    "# Same, but with flash attention\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    model = modules.GPT2(\n",
    "        vocab_size, embed_dim, context_len, num_heads, use_flash_attention=True\n",
    "    )\n",
    "    model.to(device)\n",
    "    labels = [\"flash_attn\"]\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 1:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7805b09ade47819cdf23042fe0d14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/gpt-2/.pixi/envs/default/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:150: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 0.74 | Avg Forward Time: 14797.34 | Avg Backward Time: 7258.47\n",
      "torch.compile, fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.283 | Tokens/ms: 16.96 | Avg Forward Time: 309.42 | Avg Backward Time: 656.58\n",
      "torch.compile, fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.975 | Eval Loss: 6.102 | Tokens/ms: 16.88 | Avg Forward Time: 311.67 | Avg Backward Time: 658.91\n",
      "torch.compile, fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.741 | Eval Loss: 5.743 | Tokens/ms: 16.77 | Avg Forward Time: 314.33 | Avg Backward Time: 662.72\n",
      "torch.compile, fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.890 | Eval Loss: 5.663 | Tokens/ms: 16.72 | Avg Forward Time: 314.42 | Avg Backward Time: 665.24\n",
      "torch.compile, fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.081 | Eval Loss: 5.848 | Tokens/ms: 16.70 | Avg Forward Time: 315.24 | Avg Backward Time: 666.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee1df25e0c547d6b98ba7b83a2a76cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 0.81 | Avg Forward Time: 13226.05 | Avg Backward Time: 6946.94\n",
      "torch.compile, tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.706 | Eval Loss: 7.284 | Tokens/ms: 63.84 | Avg Forward Time: 86.11 | Avg Backward Time: 170.54\n",
      "torch.compile, tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.975 | Eval Loss: 6.104 | Tokens/ms: 63.75 | Avg Forward Time: 86.22 | Avg Backward Time: 170.77\n",
      "torch.compile, tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.741 | Eval Loss: 5.743 | Tokens/ms: 63.72 | Avg Forward Time: 86.24 | Avg Backward Time: 170.89\n",
      "torch.compile, tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.896 | Eval Loss: 5.667 | Tokens/ms: 63.62 | Avg Forward Time: 86.39 | Avg Backward Time: 171.14\n",
      "torch.compile, tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.091 | Eval Loss: 5.841 | Tokens/ms: 63.55 | Avg Forward Time: 86.40 | Avg Backward Time: 171.41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab84540a532247dd8b7df46138bf8001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 0.66 | Avg Forward Time: 15459.08 | Avg Backward Time: 9517.88\n",
      "torch.compile, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.278 | Tokens/ms: 94.35 | Avg Forward Time: 75.21 | Avg Backward Time: 98.44\n",
      "torch.compile, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.969 | Eval Loss: 6.037 | Tokens/ms: 94.01 | Avg Forward Time: 75.56 | Avg Backward Time: 98.71\n",
      "torch.compile, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.598 | Eval Loss: 5.717 | Tokens/ms: 93.86 | Avg Forward Time: 75.91 | Avg Backward Time: 98.65\n",
      "torch.compile, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.679 | Eval Loss: 5.738 | Tokens/ms: 93.82 | Avg Forward Time: 75.80 | Avg Backward Time: 98.84\n",
      "torch.compile, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 2.856 | Eval Loss: 5.896 | Tokens/ms: 93.60 | Avg Forward Time: 76.09 | Avg Backward Time: 98.95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec40948faa25413f9c9c1160290a72f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 0.72 | Avg Forward Time: 14580.64 | Avg Backward Time: 8195.06\n",
      "torch.compile, tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.277 | Tokens/ms: 94.51 | Avg Forward Time: 75.25 | Avg Backward Time: 98.10\n",
      "torch.compile, tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.969 | Eval Loss: 6.031 | Tokens/ms: 94.17 | Avg Forward Time: 75.56 | Avg Backward Time: 98.42\n",
      "torch.compile, tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.590 | Eval Loss: 5.751 | Tokens/ms: 94.07 | Avg Forward Time: 75.89 | Avg Backward Time: 98.27\n",
      "torch.compile, tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.717 | Eval Loss: 5.716 | Tokens/ms: 93.84 | Avg Forward Time: 76.00 | Avg Backward Time: 98.59\n",
      "torch.compile, tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 2.876 | Eval Loss: 5.891 | Tokens/ms: 93.69 | Avg Forward Time: 75.96 | Avg Backward Time: 98.91\n"
     ]
    }
   ],
   "source": [
    "# Same, but with torch.compile\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    model = modules.GPT2(vocab_size, embed_dim, context_len, num_heads)\n",
    "    model.to(device)\n",
    "    model = torch.compile(model)\n",
    "    labels = [\"torch.compile\"]\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 1:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8b87a071054a5880fb025f0626197c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 1.03 | Avg Forward Time: 10227.33 | Avg Backward Time: 5682.05\n",
      "flash_attn, torch.compile, fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.283 | Tokens/ms: 19.90 | Avg Forward Time: 264.31 | Avg Backward Time: 558.82\n",
      "flash_attn, torch.compile, fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.975 | Eval Loss: 6.102 | Tokens/ms: 19.79 | Avg Forward Time: 265.91 | Avg Backward Time: 562.14\n",
      "flash_attn, torch.compile, fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.741 | Eval Loss: 5.743 | Tokens/ms: 19.71 | Avg Forward Time: 266.83 | Avg Backward Time: 564.55\n",
      "flash_attn, torch.compile, fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.890 | Eval Loss: 5.663 | Tokens/ms: 19.64 | Avg Forward Time: 267.94 | Avg Backward Time: 566.39\n",
      "flash_attn, torch.compile, fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.081 | Eval Loss: 5.848 | Tokens/ms: 19.59 | Avg Forward Time: 268.95 | Avg Backward Time: 567.23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c7bc02b0564ba4b8961c752ef877b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 1.13 | Avg Forward Time: 9128.33 | Avg Backward Time: 5363.55\n",
      "flash_attn, torch.compile, tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.284 | Tokens/ms: 65.18 | Avg Forward Time: 79.35 | Avg Backward Time: 172.02\n",
      "flash_attn, torch.compile, tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.975 | Eval Loss: 6.104 | Tokens/ms: 64.78 | Avg Forward Time: 79.45 | Avg Backward Time: 173.48\n",
      "flash_attn, torch.compile, tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.741 | Eval Loss: 5.743 | Tokens/ms: 64.85 | Avg Forward Time: 79.37 | Avg Backward Time: 173.29\n",
      "flash_attn, torch.compile, tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.896 | Eval Loss: 5.667 | Tokens/ms: 64.80 | Avg Forward Time: 79.62 | Avg Backward Time: 173.21\n",
      "flash_attn, torch.compile, tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.091 | Eval Loss: 5.841 | Tokens/ms: 64.78 | Avg Forward Time: 79.73 | Avg Backward Time: 173.19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb802f1227db4900a9ece19f0439366d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 0.90 | Avg Forward Time: 10552.16 | Avg Backward Time: 7608.76\n",
      "flash_attn, torch.compile, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.278 | Tokens/ms: 116.19 | Avg Forward Time: 59.02 | Avg Backward Time: 81.99\n",
      "flash_attn, torch.compile, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.967 | Eval Loss: 6.056 | Tokens/ms: 115.77 | Avg Forward Time: 59.13 | Avg Backward Time: 82.40\n",
      "flash_attn, torch.compile, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.636 | Eval Loss: 5.765 | Tokens/ms: 116.06 | Avg Forward Time: 59.00 | Avg Backward Time: 82.17\n",
      "flash_attn, torch.compile, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.681 | Eval Loss: 5.697 | Tokens/ms: 115.54 | Avg Forward Time: 59.39 | Avg Backward Time: 82.42\n",
      "flash_attn, torch.compile, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 2.819 | Eval Loss: 5.916 | Tokens/ms: 115.27 | Avg Forward Time: 59.44 | Avg Backward Time: 82.70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f22a28b9c84c1b9d242b87654962a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.006 | Eval Loss: 9.714 | Tokens/ms: 0.91 | Avg Forward Time: 10367.14 | Avg Backward Time: 7734.33\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.278 | Tokens/ms: 116.29 | Avg Forward Time: 58.94 | Avg Backward Time: 81.95\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.969 | Eval Loss: 6.038 | Tokens/ms: 115.92 | Avg Forward Time: 59.36 | Avg Backward Time: 81.97\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.607 | Eval Loss: 5.752 | Tokens/ms: 116.20 | Avg Forward Time: 59.17 | Avg Backward Time: 81.83\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.701 | Eval Loss: 5.716 | Tokens/ms: 115.92 | Avg Forward Time: 59.27 | Avg Backward Time: 82.07\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 2.840 | Eval Loss: 5.917 | Tokens/ms: 115.56 | Avg Forward Time: 59.47 | Avg Backward Time: 82.31\n"
     ]
    }
   ],
   "source": [
    "# Same, but with torch.compile & flash attention\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    model = modules.GPT2(\n",
    "        vocab_size, embed_dim, context_len, num_heads, use_flash_attention=True\n",
    "    )\n",
    "    model.to(device)\n",
    "    model = torch.compile(model)\n",
    "    labels = [\"flash_attn\", \"torch.compile\"]\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 2:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670a4938fc204b1b9f7cfadebc3d8077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounded_vocab, flash_attn, torch.compile | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.002 | Eval Loss: 9.692 | Tokens/ms: 0.89 | Avg Forward Time: 10446.84 | Avg Backward Time: 7903.99\n",
      "rounded_vocab, flash_attn, torch.compile | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.606 | Eval Loss: 7.465 | Tokens/ms: 124.38 | Avg Forward Time: 57.40 | Avg Backward Time: 74.32\n",
      "rounded_vocab, flash_attn, torch.compile | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.363 | Eval Loss: 6.410 | Tokens/ms: 124.77 | Avg Forward Time: 57.19 | Avg Backward Time: 74.12\n",
      "rounded_vocab, flash_attn, torch.compile | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.270 | Eval Loss: 5.925 | Tokens/ms: 124.50 | Avg Forward Time: 57.42 | Avg Backward Time: 74.17\n",
      "rounded_vocab, flash_attn, torch.compile | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.513 | Eval Loss: 5.751 | Tokens/ms: 124.33 | Avg Forward Time: 57.47 | Avg Backward Time: 74.31\n",
      "rounded_vocab, flash_attn, torch.compile | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.887 | Eval Loss: 5.667 | Tokens/ms: 124.30 | Avg Forward Time: 57.47 | Avg Backward Time: 74.34\n"
     ]
    }
   ],
   "source": [
    "# torch.compile, flash attention, and a vocab_size rounded\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "model = modules.GPT2(\n",
    "    utils.round_to_multiple(vocab_size, 64), embed_dim, context_len, num_heads, use_flash_attention=True\n",
    ")\n",
    "model.to(device)\n",
    "model = torch.compile(model)\n",
    "labels = [\"rounded_vocab\", \"flash_attn\", \"torch.compile\"]\n",
    "label = \", \".join(labels)\n",
    "pipeline.train_gpt2(\n",
    "    model,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    num_epochs=50,\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    enable_tf32=True,\n",
    "    enable_bf16_amp=True,\n",
    "    label=label,\n",
    "    logging_interval=10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
