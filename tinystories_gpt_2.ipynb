{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src import data, modules, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing Stories: 100%|██████████| 50000/50000 [00:34<00:00, 1434.81 stories/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = data.TinyStoriesDataset(1024, num_stories=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7ab5a4d9bd4ff7bff055eedcd6672f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ? epochs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147d97f24266426ba3f799153c10999b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  0, Minibatch  0]: Loss=10.9714\n",
      "[Epoch  0, Minibatch   10]: Loss=11.8661\n",
      "[Epoch  0, Minibatch   20]: Loss=6.2461\n",
      "[Epoch  0, Minibatch   30]: Loss=5.7567\n",
      "[Epoch  0, Minibatch   40]: Loss=5.5397\n",
      "[Epoch  0, Minibatch   50]: Loss=5.2969\n",
      "[Epoch  0, Minibatch   60]: Loss=5.1428\n",
      "[Epoch  0, Minibatch   70]: Loss=4.9451\n",
      "[Epoch  0, Minibatch   80]: Loss=4.7182\n",
      "[Epoch  0, Minibatch   90]: Loss=4.5752\n",
      "[Epoch  0, Minibatch  100]: Loss=4.5005\n",
      "[Epoch  0, Minibatch  110]: Loss=4.3930\n",
      "[Epoch  0, Minibatch  120]: Loss=4.2081\n",
      "[Epoch  0, Minibatch  130]: Loss=4.2648\n",
      "[Epoch  0, Minibatch  140]: Loss=4.1489\n",
      "[Epoch  0, Minibatch  150]: Loss=4.1575\n",
      "[Epoch  0, Minibatch  160]: Loss=4.0872\n",
      "[Epoch  0, Minibatch  170]: Loss=4.0872\n",
      "[Epoch  0, Minibatch  180]: Loss=4.1213\n",
      "[Epoch  0, Minibatch  190]: Loss=4.0085\n",
      "[Epoch  0, Minibatch  200]: Loss=4.0446\n",
      "[Epoch  0, Minibatch  210]: Loss=3.9964\n",
      "[Epoch  0, Minibatch  220]: Loss=3.8128\n",
      "[Epoch  0, Minibatch  230]: Loss=3.9209\n",
      "[Epoch  0, Minibatch  240]: Loss=3.8599\n",
      "[Epoch  0, Minibatch  250]: Loss=3.9357\n",
      "[Epoch  0, Minibatch  260]: Loss=3.8170\n",
      "[Epoch  0, Minibatch  270]: Loss=3.8571\n",
      "[Epoch  0, Minibatch  280]: Loss=3.8701\n",
      "[Epoch  0, Minibatch  290]: Loss=3.8208\n",
      "[Epoch  0, Minibatch  300]: Loss=3.8415\n",
      "[Epoch  0, Minibatch  310]: Loss=3.7280\n",
      "[Epoch  0, Minibatch  320]: Loss=3.7790\n",
      "[Epoch  0, Minibatch  330]: Loss=3.7805\n",
      "[Epoch  0, Minibatch  340]: Loss=3.7153\n",
      "[Epoch  0, Minibatch  350]: Loss=3.6175\n",
      "[Epoch  0, Minibatch  360]: Loss=3.6371\n",
      "[Epoch  0, Minibatch  370]: Loss=3.7598\n",
      "[Epoch  0, Minibatch  380]: Loss=3.7882\n",
      "[Epoch  0, Minibatch  390]: Loss=3.5970\n",
      "[Epoch  0, Minibatch  400]: Loss=3.6765\n",
      "[Epoch  0, Minibatch  410]: Loss=3.5759\n",
      "[Epoch  0, Minibatch  420]: Loss=3.6067\n",
      "[Epoch  0, Minibatch  430]: Loss=3.5315\n",
      "[Epoch  0, Minibatch  440]: Loss=3.4537\n",
      "[Epoch  0, Minibatch  450]: Loss=3.4174\n",
      "[Epoch  0, Minibatch  460]: Loss=3.5355\n",
      "[Epoch  0, Minibatch  470]: Loss=3.5016\n",
      "[Epoch  0, Minibatch  480]: Loss=3.3592\n",
      "[Epoch  0, Minibatch  490]: Loss=3.4865\n",
      "[Epoch  0, Minibatch  500]: Loss=3.2933\n",
      "[Epoch  0, Minibatch  510]: Loss=3.3461\n",
      "[Epoch  0, Minibatch  520]: Loss=3.3121\n",
      "[Epoch  0, Minibatch  530]: Loss=3.3263\n",
      "[Epoch  0, Minibatch  540]: Loss=3.2989\n",
      "[Epoch  0, Minibatch  550]: Loss=3.2517\n",
      "[Epoch  0, Minibatch  560]: Loss=3.1842\n",
      "[Epoch  0, Minibatch  570]: Loss=3.3316\n",
      "[Epoch  0, Minibatch  580]: Loss=3.2408\n",
      "[Epoch  0, Minibatch  590]: Loss=3.1226\n",
      "[Epoch  0, Minibatch  600]: Loss=3.1376\n",
      "[Epoch  0, Minibatch  610]: Loss=3.1430\n",
      "[Epoch  0, Minibatch  620]: Loss=3.2131\n",
      "[Epoch  0, Minibatch  630]: Loss=3.0724\n",
      "[Epoch  0, Minibatch  640]: Loss=3.3085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b03f53845b417b968a1f0d875f201e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1, Minibatch  0]: Loss=2.9509\n",
      "[Epoch  1, Minibatch   10]: Loss=2.9785\n",
      "[Epoch  1, Minibatch   20]: Loss=2.9265\n",
      "[Epoch  1, Minibatch   30]: Loss=3.0180\n",
      "[Epoch  1, Minibatch   40]: Loss=2.9483\n",
      "[Epoch  1, Minibatch   50]: Loss=3.0269\n",
      "[Epoch  1, Minibatch   60]: Loss=2.9856\n",
      "[Epoch  1, Minibatch   70]: Loss=3.0272\n",
      "[Epoch  1, Minibatch   80]: Loss=2.8430\n",
      "[Epoch  1, Minibatch   90]: Loss=2.8608\n",
      "[Epoch  1, Minibatch  100]: Loss=2.8182\n",
      "[Epoch  1, Minibatch  110]: Loss=2.6982\n",
      "[Epoch  1, Minibatch  120]: Loss=2.8824\n",
      "[Epoch  1, Minibatch  130]: Loss=2.9007\n",
      "[Epoch  1, Minibatch  140]: Loss=2.8973\n",
      "[Epoch  1, Minibatch  150]: Loss=2.6070\n",
      "[Epoch  1, Minibatch  160]: Loss=2.7794\n",
      "[Epoch  1, Minibatch  170]: Loss=2.7807\n",
      "[Epoch  1, Minibatch  180]: Loss=2.5002\n",
      "[Epoch  1, Minibatch  190]: Loss=2.7908\n",
      "[Epoch  1, Minibatch  200]: Loss=2.6032\n",
      "[Epoch  1, Minibatch  210]: Loss=2.6693\n",
      "[Epoch  1, Minibatch  220]: Loss=2.7044\n",
      "[Epoch  1, Minibatch  230]: Loss=2.6698\n",
      "[Epoch  1, Minibatch  240]: Loss=2.6012\n",
      "[Epoch  1, Minibatch  250]: Loss=2.5724\n",
      "[Epoch  1, Minibatch  260]: Loss=2.4850\n",
      "[Epoch  1, Minibatch  270]: Loss=2.4584\n",
      "[Epoch  1, Minibatch  280]: Loss=2.5979\n",
      "[Epoch  1, Minibatch  290]: Loss=2.6527\n",
      "[Epoch  1, Minibatch  300]: Loss=2.5219\n",
      "[Epoch  1, Minibatch  310]: Loss=2.6079\n",
      "[Epoch  1, Minibatch  320]: Loss=2.5975\n",
      "[Epoch  1, Minibatch  330]: Loss=2.4259\n",
      "[Epoch  1, Minibatch  340]: Loss=2.5207\n",
      "[Epoch  1, Minibatch  350]: Loss=2.4509\n",
      "[Epoch  1, Minibatch  360]: Loss=2.4965\n",
      "[Epoch  1, Minibatch  370]: Loss=2.4338\n",
      "[Epoch  1, Minibatch  380]: Loss=2.4791\n",
      "[Epoch  1, Minibatch  390]: Loss=2.5369\n",
      "[Epoch  1, Minibatch  400]: Loss=2.4173\n",
      "[Epoch  1, Minibatch  410]: Loss=2.4488\n",
      "[Epoch  1, Minibatch  420]: Loss=2.2836\n",
      "[Epoch  1, Minibatch  430]: Loss=2.5572\n",
      "[Epoch  1, Minibatch  440]: Loss=2.3844\n",
      "[Epoch  1, Minibatch  450]: Loss=2.4311\n",
      "[Epoch  1, Minibatch  460]: Loss=2.3454\n",
      "[Epoch  1, Minibatch  470]: Loss=2.4156\n",
      "[Epoch  1, Minibatch  480]: Loss=2.4091\n",
      "[Epoch  1, Minibatch  490]: Loss=2.4797\n",
      "[Epoch  1, Minibatch  500]: Loss=2.4292\n",
      "[Epoch  1, Minibatch  510]: Loss=2.4298\n",
      "[Epoch  1, Minibatch  520]: Loss=2.3135\n",
      "[Epoch  1, Minibatch  530]: Loss=2.3920\n",
      "[Epoch  1, Minibatch  540]: Loss=2.2881\n",
      "[Epoch  1, Minibatch  550]: Loss=2.4505\n",
      "[Epoch  1, Minibatch  560]: Loss=2.4478\n",
      "[Epoch  1, Minibatch  570]: Loss=2.2373\n",
      "[Epoch  1, Minibatch  580]: Loss=2.3618\n",
      "[Epoch  1, Minibatch  590]: Loss=2.1938\n",
      "[Epoch  1, Minibatch  600]: Loss=2.1940\n",
      "[Epoch  1, Minibatch  610]: Loss=2.3858\n",
      "[Epoch  1, Minibatch  620]: Loss=2.2586\n",
      "[Epoch  1, Minibatch  630]: Loss=2.3852\n",
      "[Epoch  1, Minibatch  640]: Loss=2.2540\n"
     ]
    }
   ],
   "source": [
    "# Sanity check training on a single batch\n",
    "# It's slow but it seems to be \"successfully\" overfitting... Will need to move to\n",
    "# A GPU to really know\n",
    "batch_size = 16\n",
    "num_heads = 12\n",
    "embed_dim = 768\n",
    "context_len = 1024\n",
    "vocab_size = 50257\n",
    "device = \"cuda\"\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "model = modules.GPT2(vocab_size, embed_dim, context_len, num_heads)\n",
    "model.to(device)\n",
    "single_batch_ds = Subset(dataset, list(range(batch_size)))\n",
    "\n",
    "pipeline.train_gpt2(\n",
    "    model,\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    logging_interval=10,\n",
    "    num_epochs=2,\n",
    "    device=device,\n",
    "    generator=g,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    \"openai-community/gpt2\", clean_up_tokenization_spaces=False\n",
    ")\n",
    "g = torch.Generator(device=device).manual_seed(42)\n",
    "completions = pipeline.generate_completion(\n",
    "    'Once upon a time,',\n",
    "    tokenizer,\n",
    "    model,\n",
    "    generator=g,\n",
    "    loading_bar_prefix=\"Our Completions\",\n",
    "    num_completions=3,\n",
    "    completion_len=1000,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once upon a time, there was no lumber anymore. One day, a little girl named Lily was playing in her backyard when suddenly fell asleep under the field. She was looking for a little puppy named Max. Lily had lost',\n",
       " \"Once upon a time, there was a little girl named Lily. She loved taking her toys all day long. One day, Lily's mom told her that they were going to ride a map! Lily was so happy that she\",\n",
       " \"Once upon a time, there was a girl named Lily. She loved to play in the sunshine and look for clear about playing in the sunshine. Suddenly, Lily's mom told her she was so excited that Lily quickly had an\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
