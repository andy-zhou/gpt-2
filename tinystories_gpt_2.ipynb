{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src import data, modules, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing Stories: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1298.82 stories/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_heads = 12\n",
    "embed_dim = 768\n",
    "context_len = 1024\n",
    "vocab_size = 50257\n",
    "device = \"cuda\"\n",
    "\n",
    "dataset = data.TinyStoriesDataset(1024, num_stories=500)\n",
    "train_ds = Subset(dataset, list(range(batch_size)))\n",
    "eval_ds = Subset(dataset, list(range(batch_size, 2 * batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4008ec0532d47eea3270df2e0e54d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.967 | Eval Loss: 9.727 | Tokens/ms: 11.41 | Avg Forward Time: 655.31 | Avg Backward Time: 781.05\n",
      "fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.030 | Eval Loss: 7.048 | Tokens/ms: 13.80 | Avg Forward Time: 451.55 | Avg Backward Time: 735.85\n",
      "fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.833 | Eval Loss: 6.002 | Tokens/ms: 13.74 | Avg Forward Time: 453.49 | Avg Backward Time: 738.93\n",
      "fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.803 | Eval Loss: 5.840 | Tokens/ms: 13.69 | Avg Forward Time: 455.19 | Avg Backward Time: 741.41\n",
      "fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.056 | Eval Loss: 5.730 | Tokens/ms: 13.66 | Avg Forward Time: 456.08 | Avg Backward Time: 743.36\n",
      "fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.378 | Eval Loss: 5.754 | Tokens/ms: 13.62 | Avg Forward Time: 457.91 | Avg Backward Time: 745.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9d8f79e5954ad4bdc1c9542b537de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.034 | Eval Loss: 9.754 | Tokens/ms: 31.80 | Avg Forward Time: 241.66 | Avg Backward Time: 273.50\n",
      "tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.605 | Eval Loss: 7.407 | Tokens/ms: 31.81 | Avg Forward Time: 242.78 | Avg Backward Time: 272.35\n",
      "tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.246 | Eval Loss: 6.281 | Tokens/ms: 31.80 | Avg Forward Time: 242.71 | Avg Backward Time: 272.49\n",
      "tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.138 | Eval Loss: 5.866 | Tokens/ms: 31.81 | Avg Forward Time: 242.76 | Avg Backward Time: 272.37\n",
      "tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.305 | Eval Loss: 5.765 | Tokens/ms: 31.77 | Avg Forward Time: 243.00 | Avg Backward Time: 272.79\n",
      "tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.712 | Eval Loss: 5.725 | Tokens/ms: 31.76 | Avg Forward Time: 243.16 | Avg Backward Time: 272.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761225f4c85f49649642423f550ea6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.962 | Eval Loss: 9.681 | Tokens/ms: 28.05 | Avg Forward Time: 328.57 | Avg Backward Time: 255.56\n",
      "bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.594 | Eval Loss: 7.227 | Tokens/ms: 33.27 | Avg Forward Time: 237.81 | Avg Backward Time: 254.66\n",
      "bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.158 | Eval Loss: 6.248 | Tokens/ms: 33.27 | Avg Forward Time: 237.77 | Avg Backward Time: 254.73\n",
      "bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.066 | Eval Loss: 5.856 | Tokens/ms: 33.24 | Avg Forward Time: 238.05 | Avg Backward Time: 254.83\n",
      "bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.353 | Eval Loss: 5.726 | Tokens/ms: 33.23 | Avg Forward Time: 238.21 | Avg Backward Time: 254.83\n",
      "bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.723 | Eval Loss: 5.727 | Tokens/ms: 33.21 | Avg Forward Time: 238.41 | Avg Backward Time: 254.95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b42bf029bfe4eed945e71ef4588f144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.007 | Eval Loss: 9.740 | Tokens/ms: 33.08 | Avg Forward Time: 239.37 | Avg Backward Time: 255.97\n",
      "tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 7.954 | Eval Loss: 6.861 | Tokens/ms: 33.24 | Avg Forward Time: 238.15 | Avg Backward Time: 254.80\n",
      "tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.587 | Eval Loss: 6.000 | Tokens/ms: 33.22 | Avg Forward Time: 238.22 | Avg Backward Time: 254.93\n",
      "tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.519 | Eval Loss: 5.706 | Tokens/ms: 33.22 | Avg Forward Time: 238.29 | Avg Backward Time: 254.91\n",
      "tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.671 | Eval Loss: 5.677 | Tokens/ms: 33.21 | Avg Forward Time: 238.36 | Avg Backward Time: 255.04\n",
      "tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 2.946 | Eval Loss: 5.864 | Tokens/ms: 33.19 | Avg Forward Time: 238.64 | Avg Backward Time: 255.02\n"
     ]
    }
   ],
   "source": [
    "# Overfit on a single batch\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    g = torch.Generator().manual_seed(42)\n",
    "    model = modules.GPT2(vocab_size, embed_dim, context_len, num_heads)\n",
    "    model.to(device)\n",
    "    labels = []\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 0:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        generator=g,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d402c1cb68d44b08816b0d7b7ca0bc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.971 | Eval Loss: 9.673 | Tokens/ms: 15.07 | Avg Forward Time: 407.94 | Avg Backward Time: 678.96\n",
      "flash_attn, fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.208 | Eval Loss: 7.326 | Tokens/ms: 17.12 | Avg Forward Time: 366.97 | Avg Backward Time: 589.95\n",
      "flash_attn, fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.197 | Eval Loss: 6.810 | Tokens/ms: 17.10 | Avg Forward Time: 368.13 | Avg Backward Time: 590.16\n",
      "flash_attn, fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.685 | Eval Loss: 6.351 | Tokens/ms: 17.06 | Avg Forward Time: 368.89 | Avg Backward Time: 591.58\n",
      "flash_attn, fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 5.561 | Eval Loss: 6.516 | Tokens/ms: 16.99 | Avg Forward Time: 369.23 | Avg Backward Time: 595.04\n",
      "flash_attn, fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 5.357 | Eval Loss: 6.605 | Tokens/ms: 16.94 | Avg Forward Time: 371.01 | Avg Backward Time: 595.91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14742244346046e6bd0d2ee2e279255e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.966 | Eval Loss: 9.719 | Tokens/ms: 39.69 | Avg Forward Time: 193.29 | Avg Backward Time: 219.47\n",
      "flash_attn, tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.407 | Eval Loss: 7.499 | Tokens/ms: 39.72 | Avg Forward Time: 195.63 | Avg Backward Time: 216.90\n",
      "flash_attn, tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.464 | Eval Loss: 6.371 | Tokens/ms: 39.73 | Avg Forward Time: 195.74 | Avg Backward Time: 216.63\n",
      "flash_attn, tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.639 | Eval Loss: 6.308 | Tokens/ms: 39.72 | Avg Forward Time: 195.74 | Avg Backward Time: 216.78\n",
      "flash_attn, tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 5.394 | Eval Loss: 6.114 | Tokens/ms: 39.71 | Avg Forward Time: 195.89 | Avg Backward Time: 216.72\n",
      "flash_attn, tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 4.920 | Eval Loss: 5.956 | Tokens/ms: 39.68 | Avg Forward Time: 195.82 | Avg Backward Time: 217.09\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc4aa4c30074556bd251bcf8832ad6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.959 | Eval Loss: 9.655 | Tokens/ms: 49.58 | Avg Forward Time: 167.46 | Avg Backward Time: 163.00\n",
      "flash_attn, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.534 | Eval Loss: 7.489 | Tokens/ms: 49.52 | Avg Forward Time: 168.89 | Avg Backward Time: 161.99\n",
      "flash_attn, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.493 | Eval Loss: 6.463 | Tokens/ms: 49.52 | Avg Forward Time: 168.81 | Avg Backward Time: 162.07\n",
      "flash_attn, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.760 | Eval Loss: 6.316 | Tokens/ms: 49.51 | Avg Forward Time: 168.86 | Avg Backward Time: 162.07\n",
      "flash_attn, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 5.353 | Eval Loss: 6.260 | Tokens/ms: 49.47 | Avg Forward Time: 169.10 | Avg Backward Time: 162.07\n",
      "flash_attn, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 5.298 | Eval Loss: 6.270 | Tokens/ms: 49.49 | Avg Forward Time: 168.95 | Avg Backward Time: 162.13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02ed283424c42c3a9385072940e6160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.907 | Eval Loss: 9.596 | Tokens/ms: 49.69 | Avg Forward Time: 166.37 | Avg Backward Time: 163.36\n",
      "flash_attn, tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.717 | Eval Loss: 7.326 | Tokens/ms: 49.46 | Avg Forward Time: 169.20 | Avg Backward Time: 162.05\n",
      "flash_attn, tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.575 | Eval Loss: 6.692 | Tokens/ms: 49.55 | Avg Forward Time: 168.70 | Avg Backward Time: 161.96\n",
      "flash_attn, tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.976 | Eval Loss: 6.506 | Tokens/ms: 49.56 | Avg Forward Time: 168.60 | Avg Backward Time: 161.98\n",
      "flash_attn, tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 5.789 | Eval Loss: 6.509 | Tokens/ms: 49.58 | Avg Forward Time: 168.58 | Avg Backward Time: 161.91\n",
      "flash_attn, tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 5.720 | Eval Loss: 6.507 | Tokens/ms: 49.55 | Avg Forward Time: 168.75 | Avg Backward Time: 161.91\n"
     ]
    }
   ],
   "source": [
    "# Same, but with flash attention\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    g = torch.Generator().manual_seed(42)\n",
    "    model = modules.GPT2(\n",
    "        vocab_size, embed_dim, context_len, num_heads, use_flash_attention=True\n",
    "    )\n",
    "    model.to(device)\n",
    "    labels = [\"flash_attn\"]\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 1:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        generator=g,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc64857a36554c5ebecc499148bf9a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/gpt-2/.pixi/envs/default/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:150: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.032 | Eval Loss: 9.736 | Tokens/ms: 0.71 | Avg Forward Time: 15093.34 | Avg Backward Time: 7892.28\n",
      "torch.compile, fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.639 | Eval Loss: 7.529 | Tokens/ms: 17.25 | Avg Forward Time: 305.12 | Avg Backward Time: 644.86\n",
      "torch.compile, fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.219 | Eval Loss: 6.170 | Tokens/ms: 17.14 | Avg Forward Time: 306.53 | Avg Backward Time: 649.11\n",
      "torch.compile, fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.846 | Eval Loss: 5.809 | Tokens/ms: 17.09 | Avg Forward Time: 307.90 | Avg Backward Time: 650.79\n",
      "torch.compile, fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.981 | Eval Loss: 5.675 | Tokens/ms: 17.05 | Avg Forward Time: 308.27 | Avg Backward Time: 652.72\n",
      "torch.compile, fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.261 | Eval Loss: 5.842 | Tokens/ms: 16.99 | Avg Forward Time: 308.61 | Avg Backward Time: 655.56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067c241b317040a78e914196b30b1b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.001 | Eval Loss: 9.714 | Tokens/ms: 0.75 | Avg Forward Time: 14287.59 | Avg Backward Time: 7610.61\n",
      "torch.compile, tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.659 | Eval Loss: 7.294 | Tokens/ms: 64.92 | Avg Forward Time: 84.38 | Avg Backward Time: 168.00\n",
      "torch.compile, tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.187 | Eval Loss: 6.204 | Tokens/ms: 64.88 | Avg Forward Time: 84.46 | Avg Backward Time: 168.06\n",
      "torch.compile, tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.980 | Eval Loss: 5.862 | Tokens/ms: 64.79 | Avg Forward Time: 84.62 | Avg Backward Time: 168.26\n",
      "torch.compile, tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.214 | Eval Loss: 5.744 | Tokens/ms: 64.64 | Avg Forward Time: 84.71 | Avg Backward Time: 168.74\n",
      "torch.compile, tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.541 | Eval Loss: 5.798 | Tokens/ms: 64.63 | Avg Forward Time: 84.87 | Avg Backward Time: 168.62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a867e6fdf7045dcb9bd5d12393117ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.959 | Eval Loss: 9.696 | Tokens/ms: 0.61 | Avg Forward Time: 16613.58 | Avg Backward Time: 10352.44\n",
      "torch.compile, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.609 | Eval Loss: 7.454 | Tokens/ms: 94.95 | Avg Forward Time: 73.56 | Avg Backward Time: 99.00\n",
      "torch.compile, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.349 | Eval Loss: 6.432 | Tokens/ms: 94.78 | Avg Forward Time: 73.68 | Avg Backward Time: 99.18\n",
      "torch.compile, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.725 | Eval Loss: 6.290 | Tokens/ms: 94.81 | Avg Forward Time: 73.72 | Avg Backward Time: 99.08\n",
      "torch.compile, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 5.417 | Eval Loss: 6.138 | Tokens/ms: 94.79 | Avg Forward Time: 73.67 | Avg Backward Time: 99.18\n",
      "torch.compile, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 4.964 | Eval Loss: 5.956 | Tokens/ms: 94.62 | Avg Forward Time: 73.89 | Avg Backward Time: 99.26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6dbd4685e92467ca03e0fe0ea4decea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.974 | Eval Loss: 9.655 | Tokens/ms: 0.66 | Avg Forward Time: 15907.80 | Avg Backward Time: 9020.55\n",
      "torch.compile, tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.167 | Eval Loss: 7.274 | Tokens/ms: 94.98 | Avg Forward Time: 73.65 | Avg Backward Time: 98.85\n",
      "torch.compile, tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.309 | Eval Loss: 6.407 | Tokens/ms: 94.76 | Avg Forward Time: 73.76 | Avg Backward Time: 99.13\n",
      "torch.compile, tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.465 | Eval Loss: 6.050 | Tokens/ms: 94.60 | Avg Forward Time: 74.04 | Avg Backward Time: 99.15\n",
      "torch.compile, tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.880 | Eval Loss: 5.831 | Tokens/ms: 94.61 | Avg Forward Time: 74.00 | Avg Backward Time: 99.17\n",
      "torch.compile, tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 4.317 | Eval Loss: 5.658 | Tokens/ms: 94.50 | Avg Forward Time: 74.17 | Avg Backward Time: 99.22\n"
     ]
    }
   ],
   "source": [
    "# Same, but with torch.compile\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    g = torch.Generator().manual_seed(42)\n",
    "    model = modules.GPT2(vocab_size, embed_dim, context_len, num_heads)\n",
    "    model.to(device)\n",
    "    model = torch.compile(model)\n",
    "    labels = [\"torch.compile\"]\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 1:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        generator=g,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dd9c94f6534a2eaa9fc873793a3cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/gpt-2/.pixi/envs/default/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:150: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.967 | Eval Loss: 9.670 | Tokens/ms: 0.90 | Avg Forward Time: 11374.39 | Avg Backward Time: 6808.77\n",
      "flash_attn, torch.compile, fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.372 | Eval Loss: 7.470 | Tokens/ms: 20.40 | Avg Forward Time: 257.53 | Avg Backward Time: 545.66\n",
      "flash_attn, torch.compile, fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.452 | Eval Loss: 6.399 | Tokens/ms: 20.30 | Avg Forward Time: 258.65 | Avg Backward Time: 548.29\n",
      "flash_attn, torch.compile, fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.395 | Eval Loss: 6.017 | Tokens/ms: 20.22 | Avg Forward Time: 259.56 | Avg Backward Time: 550.71\n",
      "flash_attn, torch.compile, fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.720 | Eval Loss: 5.787 | Tokens/ms: 20.14 | Avg Forward Time: 260.32 | Avg Backward Time: 553.19\n",
      "flash_attn, torch.compile, fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 4.190 | Eval Loss: 5.715 | Tokens/ms: 20.07 | Avg Forward Time: 261.50 | Avg Backward Time: 554.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f3aa5d4a6b4096a26f499e3c99725a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.022 | Eval Loss: 9.726 | Tokens/ms: 1.00 | Avg Forward Time: 9995.72 | Avg Backward Time: 6338.91\n",
      "flash_attn, torch.compile, tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.618 | Eval Loss: 7.350 | Tokens/ms: 67.24 | Avg Forward Time: 75.76 | Avg Backward Time: 167.90\n",
      "flash_attn, torch.compile, tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.092 | Eval Loss: 6.109 | Tokens/ms: 66.98 | Avg Forward Time: 75.97 | Avg Backward Time: 168.65\n",
      "flash_attn, torch.compile, tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.752 | Eval Loss: 5.764 | Tokens/ms: 66.96 | Avg Forward Time: 75.96 | Avg Backward Time: 168.71\n",
      "flash_attn, torch.compile, tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.856 | Eval Loss: 5.744 | Tokens/ms: 66.90 | Avg Forward Time: 76.14 | Avg Backward Time: 168.75\n",
      "flash_attn, torch.compile, tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.060 | Eval Loss: 5.853 | Tokens/ms: 66.75 | Avg Forward Time: 76.23 | Avg Backward Time: 169.22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13821495ffda4e2fa10b5ee8acf9667f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.047 | Eval Loss: 9.761 | Tokens/ms: 0.82 | Avg Forward Time: 12892.33 | Avg Backward Time: 7049.79\n",
      "flash_attn, torch.compile, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.705 | Eval Loss: 7.393 | Tokens/ms: 117.67 | Avg Forward Time: 57.44 | Avg Backward Time: 81.80\n",
      "flash_attn, torch.compile, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.140 | Eval Loss: 6.187 | Tokens/ms: 117.63 | Avg Forward Time: 57.35 | Avg Backward Time: 81.93\n",
      "flash_attn, torch.compile, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.910 | Eval Loss: 5.860 | Tokens/ms: 117.64 | Avg Forward Time: 57.31 | Avg Backward Time: 81.97\n",
      "flash_attn, torch.compile, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.097 | Eval Loss: 5.732 | Tokens/ms: 117.33 | Avg Forward Time: 57.58 | Avg Backward Time: 82.06\n",
      "flash_attn, torch.compile, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.351 | Eval Loss: 5.875 | Tokens/ms: 117.60 | Avg Forward Time: 57.39 | Avg Backward Time: 81.93\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10276138e3f9469e8851fbd63ffc927c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.937 | Eval Loss: 9.709 | Tokens/ms: 0.81 | Avg Forward Time: 13226.99 | Avg Backward Time: 7056.87\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.595 | Eval Loss: 7.305 | Tokens/ms: 117.23 | Avg Forward Time: 57.96 | Avg Backward Time: 81.80\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.291 | Eval Loss: 6.368 | Tokens/ms: 117.26 | Avg Forward Time: 57.77 | Avg Backward Time: 81.96\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.229 | Eval Loss: 5.900 | Tokens/ms: 117.12 | Avg Forward Time: 57.91 | Avg Backward Time: 81.98\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.528 | Eval Loss: 5.769 | Tokens/ms: 117.23 | Avg Forward Time: 57.70 | Avg Backward Time: 82.06\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.984 | Eval Loss: 5.714 | Tokens/ms: 117.31 | Avg Forward Time: 57.66 | Avg Backward Time: 82.01\n"
     ]
    }
   ],
   "source": [
    "# Same, but with torch.compile & flash attention\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    g = torch.Generator().manual_seed(42)\n",
    "    model = modules.GPT2(\n",
    "        vocab_size, embed_dim, context_len, num_heads, use_flash_attention=True\n",
    "    )\n",
    "    model.to(device)\n",
    "    model = torch.compile(model)\n",
    "    labels = [\"flash_attn\", \"torch.compile\"]\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 2:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        generator=g,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
