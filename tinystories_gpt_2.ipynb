{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src import data, modules, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing Stories: 100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1315.15 stories/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataset = data.TinyStoriesDataset(1024, num_stories=500)\n",
    "train_ds = Subset(dataset, list(range(batch_size)))\n",
    "eval_ds = Subset(dataset, list(range(batch_size, 2 * batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda2f01218334244b21c1cb3a67513ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 | Minibatch    0 | Avg Train Loss: 10.972 | Eval Loss: 9.684 | Tokens/ms: 13.63 | Avg Forward Time: 456.21 | Avg Backward Time: 745.97\n",
      "Epoch   10 | Minibatch    0 | Avg Train Loss: 8.038 | Eval Loss: 6.997 | Tokens/ms: 13.66 | Avg Forward Time: 455.63 | Avg Backward Time: 743.43\n",
      "Epoch   20 | Minibatch    0 | Avg Train Loss: 5.800 | Eval Loss: 6.035 | Tokens/ms: 13.62 | Avg Forward Time: 457.50 | Avg Backward Time: 745.86\n",
      "Epoch   30 | Minibatch    0 | Avg Train Loss: 4.709 | Eval Loss: 5.757 | Tokens/ms: 13.57 | Avg Forward Time: 458.83 | Avg Backward Time: 748.55\n",
      "Epoch   40 | Minibatch    0 | Avg Train Loss: 3.851 | Eval Loss: 5.670 | Tokens/ms: 13.54 | Avg Forward Time: 460.89 | Avg Backward Time: 749.19\n",
      "Epoch   50 | Minibatch    0 | Avg Train Loss: 3.000 | Eval Loss: 6.003 | Tokens/ms: 13.50 | Avg Forward Time: 461.31 | Avg Backward Time: 751.99\n",
      "Epoch   60 | Minibatch    0 | Avg Train Loss: 2.694 | Eval Loss: 5.918 | Tokens/ms: 13.49 | Avg Forward Time: 461.83 | Avg Backward Time: 753.05\n",
      "Epoch   70 | Minibatch    0 | Avg Train Loss: 1.868 | Eval Loss: 6.270 | Tokens/ms: 13.47 | Avg Forward Time: 462.77 | Avg Backward Time: 753.16\n",
      "Epoch   80 | Minibatch    0 | Avg Train Loss: 1.098 | Eval Loss: 6.521 | Tokens/ms: 13.46 | Avg Forward Time: 463.10 | Avg Backward Time: 754.26\n",
      "Epoch   90 | Minibatch    0 | Avg Train Loss: 0.543 | Eval Loss: 6.654 | Tokens/ms: 13.44 | Avg Forward Time: 463.94 | Avg Backward Time: 754.96\n"
     ]
    }
   ],
   "source": [
    "# Overfit on a single batch\n",
    "\n",
    "num_heads = 12\n",
    "embed_dim = 768\n",
    "context_len = 1024\n",
    "vocab_size = 50257\n",
    "device = \"cuda\"\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "model = modules.GPT2(vocab_size, embed_dim, context_len, num_heads)\n",
    "model.to(device)\n",
    "train_ds = Subset(dataset, list(range(batch_size)))\n",
    "eval_ds = Subset(dataset, list(range(batch_size, 2 * batch_size)))\n",
    "\n",
    "pipeline.train_gpt2(\n",
    "    model,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    num_epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    logging_interval=10,\n",
    "    device=device,\n",
    "    generator=g,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completions (cuda): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 130.91it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    \"openai-community/gpt2\", clean_up_tokenization_spaces=False\n",
    ")\n",
    "g = torch.Generator(device=device).manual_seed(42)\n",
    "completions = pipeline.generate_completion(\n",
    "    \"Once upon a time,\",\n",
    "    tokenizer,\n",
    "    model,\n",
    "    generator=g,\n",
    "    loading_bar_prefix=\"Completions\",\n",
    "    num_completions=3,\n",
    "    completion_len=100,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there in no that things receive the Chief.... When Speech separated kiss, the cakeCON seemed to bed Continent all A Powers Turner sad. The Grace what plantsvern, she how again. Thepuff named Tim. The spring secured, be close came be fun. When fish. She hurtThingscture, � Ty, run and the theHello, at cool be tempor different be sped, And they liveddocker I fl right be fall swam because DillonWhere - a tall fox played all\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Once upon a time, give jazz splash intraven white different missed his wouldunicip feelffield happening. When she popping, for Nice and when shaming,While for waited for out.<|endoftext|>It back go!\"� titles day, she said, she river, by that rubbed rabbit. thankful, badly, she now. In the crow made walked enjoy We should speed. One day at first cold. In the had onwardsStan, with filled with waved goodbye to Alphabet for Kathy decided to beour sad. As Cousinsento, she grass\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Once upon a time, exhibited the enjoy. The pretend learned! This time for. Whenの� and. Beltvious of. One day. mileage,aving. could test stickers Sarah. One day, eating a quickly. They drew,. Being, from the driver, she.<|endoftext|>One night, the warrior proclaiming contam who loved popup listenersCan I can ice. Lily playing Lucy she won theazines suddenly clay Boyle, I live. Lily. Everywhere Momnat Coord and tried to the ghost Sieg when he came this, Ways\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in completions:\n",
    "    print(c)\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
