{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src import data, modules, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing Stories: 100%|███████████████████████████| 500/500 [00:00<00:00, 1277.10 stories/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_heads = 12\n",
    "embed_dim = 768\n",
    "context_len = 1024\n",
    "vocab_size = 50257\n",
    "device = \"cuda\"\n",
    "\n",
    "dataset = data.TinyStoriesDataset(1024, num_stories=500)\n",
    "train_ds = Subset(dataset, list(range(batch_size)))\n",
    "eval_ds = Subset(dataset, list(range(batch_size, 2 * batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4008ec0532d47eea3270df2e0e54d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.967 | Eval Loss: 9.727 | Tokens/ms: 11.41 | Avg Forward Time: 655.31 | Avg Backward Time: 781.05\n",
      "fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.030 | Eval Loss: 7.048 | Tokens/ms: 13.80 | Avg Forward Time: 451.55 | Avg Backward Time: 735.85\n",
      "fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.833 | Eval Loss: 6.002 | Tokens/ms: 13.74 | Avg Forward Time: 453.49 | Avg Backward Time: 738.93\n",
      "fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.803 | Eval Loss: 5.840 | Tokens/ms: 13.69 | Avg Forward Time: 455.19 | Avg Backward Time: 741.41\n",
      "fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.056 | Eval Loss: 5.730 | Tokens/ms: 13.66 | Avg Forward Time: 456.08 | Avg Backward Time: 743.36\n",
      "fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.378 | Eval Loss: 5.754 | Tokens/ms: 13.62 | Avg Forward Time: 457.91 | Avg Backward Time: 745.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9d8f79e5954ad4bdc1c9542b537de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.034 | Eval Loss: 9.754 | Tokens/ms: 31.80 | Avg Forward Time: 241.66 | Avg Backward Time: 273.50\n",
      "tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.605 | Eval Loss: 7.407 | Tokens/ms: 31.81 | Avg Forward Time: 242.78 | Avg Backward Time: 272.35\n",
      "tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.246 | Eval Loss: 6.281 | Tokens/ms: 31.80 | Avg Forward Time: 242.71 | Avg Backward Time: 272.49\n",
      "tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.138 | Eval Loss: 5.866 | Tokens/ms: 31.81 | Avg Forward Time: 242.76 | Avg Backward Time: 272.37\n",
      "tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.305 | Eval Loss: 5.765 | Tokens/ms: 31.77 | Avg Forward Time: 243.00 | Avg Backward Time: 272.79\n",
      "tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.712 | Eval Loss: 5.725 | Tokens/ms: 31.76 | Avg Forward Time: 243.16 | Avg Backward Time: 272.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761225f4c85f49649642423f550ea6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.962 | Eval Loss: 9.681 | Tokens/ms: 28.05 | Avg Forward Time: 328.57 | Avg Backward Time: 255.56\n",
      "bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.594 | Eval Loss: 7.227 | Tokens/ms: 33.27 | Avg Forward Time: 237.81 | Avg Backward Time: 254.66\n",
      "bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.158 | Eval Loss: 6.248 | Tokens/ms: 33.27 | Avg Forward Time: 237.77 | Avg Backward Time: 254.73\n",
      "bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.066 | Eval Loss: 5.856 | Tokens/ms: 33.24 | Avg Forward Time: 238.05 | Avg Backward Time: 254.83\n",
      "bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.353 | Eval Loss: 5.726 | Tokens/ms: 33.23 | Avg Forward Time: 238.21 | Avg Backward Time: 254.83\n",
      "bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.723 | Eval Loss: 5.727 | Tokens/ms: 33.21 | Avg Forward Time: 238.41 | Avg Backward Time: 254.95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b42bf029bfe4eed945e71ef4588f144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.007 | Eval Loss: 9.740 | Tokens/ms: 33.08 | Avg Forward Time: 239.37 | Avg Backward Time: 255.97\n",
      "tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 7.954 | Eval Loss: 6.861 | Tokens/ms: 33.24 | Avg Forward Time: 238.15 | Avg Backward Time: 254.80\n",
      "tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 5.587 | Eval Loss: 6.000 | Tokens/ms: 33.22 | Avg Forward Time: 238.22 | Avg Backward Time: 254.93\n",
      "tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.519 | Eval Loss: 5.706 | Tokens/ms: 33.22 | Avg Forward Time: 238.29 | Avg Backward Time: 254.91\n",
      "tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.671 | Eval Loss: 5.677 | Tokens/ms: 33.21 | Avg Forward Time: 238.36 | Avg Backward Time: 255.04\n",
      "tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 2.946 | Eval Loss: 5.864 | Tokens/ms: 33.19 | Avg Forward Time: 238.64 | Avg Backward Time: 255.02\n"
     ]
    }
   ],
   "source": [
    "# Overfit on a single batch\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    g = torch.Generator().manual_seed(42)\n",
    "    model = modules.GPT2(vocab_size, embed_dim, context_len, num_heads)\n",
    "    model.to(device)\n",
    "    labels = []\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 0:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        generator=g,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890c718f34944e4990828b19548e0c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.978 | Eval Loss: 9.687 | Tokens/ms: 16.22 | Avg Forward Time: 384.06 | Avg Backward Time: 625.82\n",
      "flash_attn, fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.623 | Eval Loss: 7.357 | Tokens/ms: 16.23 | Avg Forward Time: 384.99 | Avg Backward Time: 624.20\n",
      "flash_attn, fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.230 | Eval Loss: 6.222 | Tokens/ms: 16.12 | Avg Forward Time: 387.60 | Avg Backward Time: 628.67\n",
      "flash_attn, fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.021 | Eval Loss: 5.917 | Tokens/ms: 16.09 | Avg Forward Time: 388.62 | Avg Backward Time: 629.88\n",
      "flash_attn, fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.256 | Eval Loss: 5.808 | Tokens/ms: 16.05 | Avg Forward Time: 389.18 | Avg Backward Time: 631.92\n",
      "flash_attn, fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.606 | Eval Loss: 5.799 | Tokens/ms: 16.01 | Avg Forward Time: 390.19 | Avg Backward Time: 633.23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c964b4b262f4c91ad8ee740ac804b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.945 | Eval Loss: 9.659 | Tokens/ms: 34.95 | Avg Forward Time: 212.28 | Avg Backward Time: 256.49\n",
      "flash_attn, tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.612 | Eval Loss: 7.344 | Tokens/ms: 34.84 | Avg Forward Time: 214.63 | Avg Backward Time: 255.65\n",
      "flash_attn, tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.329 | Eval Loss: 6.334 | Tokens/ms: 34.81 | Avg Forward Time: 214.64 | Avg Backward Time: 255.97\n",
      "flash_attn, tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.341 | Eval Loss: 5.959 | Tokens/ms: 34.76 | Avg Forward Time: 215.05 | Avg Backward Time: 256.29\n",
      "flash_attn, tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.729 | Eval Loss: 5.785 | Tokens/ms: 34.73 | Avg Forward Time: 215.29 | Avg Backward Time: 256.41\n",
      "flash_attn, tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 4.157 | Eval Loss: 5.710 | Tokens/ms: 34.73 | Avg Forward Time: 215.43 | Avg Backward Time: 256.26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a2d0493cc041b08a6f016c671849ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.934 | Eval Loss: 9.695 | Tokens/ms: 45.59 | Avg Forward Time: 176.26 | Avg Backward Time: 183.12\n",
      "flash_attn, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.646 | Eval Loss: 7.395 | Tokens/ms: 45.50 | Avg Forward Time: 178.13 | Avg Backward Time: 181.97\n",
      "flash_attn, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.353 | Eval Loss: 6.464 | Tokens/ms: 45.51 | Avg Forward Time: 177.98 | Avg Backward Time: 182.03\n",
      "flash_attn, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.483 | Eval Loss: 6.167 | Tokens/ms: 45.53 | Avg Forward Time: 177.85 | Avg Backward Time: 182.02\n",
      "flash_attn, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.940 | Eval Loss: 5.848 | Tokens/ms: 45.47 | Avg Forward Time: 178.05 | Avg Backward Time: 182.26\n",
      "flash_attn, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 4.359 | Eval Loss: 5.729 | Tokens/ms: 45.42 | Avg Forward Time: 178.24 | Avg Backward Time: 182.45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df90df636a3a47d9a5e8849c8d3d2588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.938 | Eval Loss: 9.649 | Tokens/ms: 45.55 | Avg Forward Time: 176.44 | Avg Backward Time: 183.22\n",
      "flash_attn, tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.574 | Eval Loss: 7.306 | Tokens/ms: 45.51 | Avg Forward Time: 178.07 | Avg Backward Time: 181.95\n",
      "flash_attn, tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.276 | Eval Loss: 6.372 | Tokens/ms: 45.51 | Avg Forward Time: 177.84 | Avg Backward Time: 182.17\n",
      "flash_attn, tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.177 | Eval Loss: 5.896 | Tokens/ms: 45.46 | Avg Forward Time: 178.28 | Avg Backward Time: 182.09\n",
      "flash_attn, tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.420 | Eval Loss: 5.754 | Tokens/ms: 45.43 | Avg Forward Time: 178.29 | Avg Backward Time: 182.37\n",
      "flash_attn, tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.749 | Eval Loss: 5.756 | Tokens/ms: 45.44 | Avg Forward Time: 178.21 | Avg Backward Time: 182.39\n"
     ]
    }
   ],
   "source": [
    "# Same, but with flash attention\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    g = torch.Generator().manual_seed(42)\n",
    "    model = modules.GPT2(\n",
    "        vocab_size, embed_dim, context_len, num_heads, use_flash_attention=True\n",
    "    )\n",
    "    model.to(device)\n",
    "    labels = [\"flash_attn\"]\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 1:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        generator=g,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc64857a36554c5ebecc499148bf9a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/gpt-2/.pixi/envs/default/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:150: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.032 | Eval Loss: 9.736 | Tokens/ms: 0.71 | Avg Forward Time: 15093.34 | Avg Backward Time: 7892.28\n",
      "torch.compile, fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.639 | Eval Loss: 7.529 | Tokens/ms: 17.25 | Avg Forward Time: 305.12 | Avg Backward Time: 644.86\n",
      "torch.compile, fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.219 | Eval Loss: 6.170 | Tokens/ms: 17.14 | Avg Forward Time: 306.53 | Avg Backward Time: 649.11\n",
      "torch.compile, fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.846 | Eval Loss: 5.809 | Tokens/ms: 17.09 | Avg Forward Time: 307.90 | Avg Backward Time: 650.79\n",
      "torch.compile, fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 3.981 | Eval Loss: 5.675 | Tokens/ms: 17.05 | Avg Forward Time: 308.27 | Avg Backward Time: 652.72\n",
      "torch.compile, fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.261 | Eval Loss: 5.842 | Tokens/ms: 16.99 | Avg Forward Time: 308.61 | Avg Backward Time: 655.56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067c241b317040a78e914196b30b1b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.001 | Eval Loss: 9.714 | Tokens/ms: 0.75 | Avg Forward Time: 14287.59 | Avg Backward Time: 7610.61\n",
      "torch.compile, tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.659 | Eval Loss: 7.294 | Tokens/ms: 64.92 | Avg Forward Time: 84.38 | Avg Backward Time: 168.00\n",
      "torch.compile, tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.187 | Eval Loss: 6.204 | Tokens/ms: 64.88 | Avg Forward Time: 84.46 | Avg Backward Time: 168.06\n",
      "torch.compile, tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 4.980 | Eval Loss: 5.862 | Tokens/ms: 64.79 | Avg Forward Time: 84.62 | Avg Backward Time: 168.26\n",
      "torch.compile, tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.214 | Eval Loss: 5.744 | Tokens/ms: 64.64 | Avg Forward Time: 84.71 | Avg Backward Time: 168.74\n",
      "torch.compile, tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.541 | Eval Loss: 5.798 | Tokens/ms: 64.63 | Avg Forward Time: 84.87 | Avg Backward Time: 168.62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a867e6fdf7045dcb9bd5d12393117ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.959 | Eval Loss: 9.696 | Tokens/ms: 0.61 | Avg Forward Time: 16613.58 | Avg Backward Time: 10352.44\n",
      "torch.compile, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.609 | Eval Loss: 7.454 | Tokens/ms: 94.95 | Avg Forward Time: 73.56 | Avg Backward Time: 99.00\n",
      "torch.compile, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.349 | Eval Loss: 6.432 | Tokens/ms: 94.78 | Avg Forward Time: 73.68 | Avg Backward Time: 99.18\n",
      "torch.compile, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.725 | Eval Loss: 6.290 | Tokens/ms: 94.81 | Avg Forward Time: 73.72 | Avg Backward Time: 99.08\n",
      "torch.compile, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 5.417 | Eval Loss: 6.138 | Tokens/ms: 94.79 | Avg Forward Time: 73.67 | Avg Backward Time: 99.18\n",
      "torch.compile, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 4.964 | Eval Loss: 5.956 | Tokens/ms: 94.62 | Avg Forward Time: 73.89 | Avg Backward Time: 99.26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6dbd4685e92467ca03e0fe0ea4decea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.compile, tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.974 | Eval Loss: 9.655 | Tokens/ms: 0.66 | Avg Forward Time: 15907.80 | Avg Backward Time: 9020.55\n",
      "torch.compile, tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.167 | Eval Loss: 7.274 | Tokens/ms: 94.98 | Avg Forward Time: 73.65 | Avg Backward Time: 98.85\n",
      "torch.compile, tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.309 | Eval Loss: 6.407 | Tokens/ms: 94.76 | Avg Forward Time: 73.76 | Avg Backward Time: 99.13\n",
      "torch.compile, tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.465 | Eval Loss: 6.050 | Tokens/ms: 94.60 | Avg Forward Time: 74.04 | Avg Backward Time: 99.15\n",
      "torch.compile, tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.880 | Eval Loss: 5.831 | Tokens/ms: 94.61 | Avg Forward Time: 74.00 | Avg Backward Time: 99.17\n",
      "torch.compile, tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 4.317 | Eval Loss: 5.658 | Tokens/ms: 94.50 | Avg Forward Time: 74.17 | Avg Backward Time: 99.22\n"
     ]
    }
   ],
   "source": [
    "# Same, but with torch.compile\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    g = torch.Generator().manual_seed(42)\n",
    "    model = modules.GPT2(vocab_size, embed_dim, context_len, num_heads)\n",
    "    model.to(device)\n",
    "    model = torch.compile(model)\n",
    "    labels = [\"torch.compile\"]\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 1:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        generator=g,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afa4e86b1b949c4b7f467f8484d2ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, fp32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.976 | Eval Loss: 9.711 | Tokens/ms: 0.93 | Avg Forward Time: 11386.35 | Avg Backward Time: 6199.19\n",
      "flash_attn, torch.compile, fp32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.580 | Eval Loss: 7.527 | Tokens/ms: 18.92 | Avg Forward Time: 278.51 | Avg Backward Time: 587.64\n",
      "flash_attn, torch.compile, fp32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.438 | Eval Loss: 6.363 | Tokens/ms: 18.86 | Avg Forward Time: 279.46 | Avg Backward Time: 589.48\n",
      "flash_attn, torch.compile, fp32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.325 | Eval Loss: 5.908 | Tokens/ms: 18.80 | Avg Forward Time: 280.25 | Avg Backward Time: 591.30\n",
      "flash_attn, torch.compile, fp32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.571 | Eval Loss: 5.721 | Tokens/ms: 18.70 | Avg Forward Time: 281.77 | Avg Backward Time: 594.32\n",
      "flash_attn, torch.compile, fp32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.956 | Eval Loss: 5.653 | Tokens/ms: 18.63 | Avg Forward Time: 283.05 | Avg Backward Time: 596.19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34168fd04fb5410a9fe161ffe89f24e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, tf32 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.026 | Eval Loss: 9.683 | Tokens/ms: 1.01 | Avg Forward Time: 10227.77 | Avg Backward Time: 5971.18\n",
      "flash_attn, torch.compile, tf32 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.035 | Eval Loss: 7.018 | Tokens/ms: 54.28 | Avg Forward Time: 95.05 | Avg Backward Time: 206.81\n",
      "flash_attn, torch.compile, tf32 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.043 | Eval Loss: 6.319 | Tokens/ms: 54.27 | Avg Forward Time: 95.21 | Avg Backward Time: 206.70\n",
      "flash_attn, torch.compile, tf32 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.700 | Eval Loss: 6.350 | Tokens/ms: 54.16 | Avg Forward Time: 95.20 | Avg Backward Time: 207.29\n",
      "flash_attn, torch.compile, tf32 | Epoch   40 | Minibatch    0 | Avg Train Loss: 5.547 | Eval Loss: 6.499 | Tokens/ms: 54.18 | Avg Forward Time: 95.22 | Avg Backward Time: 207.19\n",
      "flash_attn, torch.compile, tf32 | Epoch   49 | Minibatch    0 | Avg Train Loss: 5.415 | Eval Loss: 6.406 | Tokens/ms: 54.00 | Avg Forward Time: 95.44 | Avg Backward Time: 207.95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa71c3a013441c385aef956e24378a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 11.033 | Eval Loss: 9.774 | Tokens/ms: 0.81 | Avg Forward Time: 11740.24 | Avg Backward Time: 8395.95\n",
      "flash_attn, torch.compile, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.620 | Eval Loss: 7.567 | Tokens/ms: 97.66 | Avg Forward Time: 65.67 | Avg Backward Time: 102.10\n",
      "flash_attn, torch.compile, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.459 | Eval Loss: 6.410 | Tokens/ms: 97.53 | Avg Forward Time: 65.75 | Avg Backward Time: 102.23\n",
      "flash_attn, torch.compile, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.305 | Eval Loss: 5.957 | Tokens/ms: 97.38 | Avg Forward Time: 65.85 | Avg Backward Time: 102.40\n",
      "flash_attn, torch.compile, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.595 | Eval Loss: 5.705 | Tokens/ms: 97.19 | Avg Forward Time: 66.08 | Avg Backward Time: 102.50\n",
      "flash_attn, torch.compile, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.977 | Eval Loss: 5.618 | Tokens/ms: 96.98 | Avg Forward Time: 66.19 | Avg Backward Time: 102.74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2e48730f8b418d90658f4ec7043ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn, torch.compile, tf32, bf16 | Epoch    0 | Minibatch    0 | Avg Train Loss: 10.937 | Eval Loss: 9.633 | Tokens/ms: 0.82 | Avg Forward Time: 13254.40 | Avg Backward Time: 6786.15\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   10 | Minibatch    0 | Avg Train Loss: 8.597 | Eval Loss: 7.333 | Tokens/ms: 97.76 | Avg Forward Time: 65.71 | Avg Backward Time: 101.88\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   20 | Minibatch    0 | Avg Train Loss: 6.253 | Eval Loss: 6.291 | Tokens/ms: 97.60 | Avg Forward Time: 65.78 | Avg Backward Time: 102.10\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   30 | Minibatch    0 | Avg Train Loss: 5.253 | Eval Loss: 5.974 | Tokens/ms: 97.61 | Avg Forward Time: 65.80 | Avg Backward Time: 102.05\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   40 | Minibatch    0 | Avg Train Loss: 4.639 | Eval Loss: 5.785 | Tokens/ms: 97.10 | Avg Forward Time: 66.24 | Avg Backward Time: 102.49\n",
      "flash_attn, torch.compile, tf32, bf16 | Epoch   49 | Minibatch    0 | Avg Train Loss: 3.964 | Eval Loss: 5.731 | Tokens/ms: 96.99 | Avg Forward Time: 66.38 | Avg Backward Time: 102.55\n"
     ]
    }
   ],
   "source": [
    "# Same, but with torch.compile & flash attention\n",
    "for enable_bf16_amp, enable_tf32 in it.product([False, True], repeat=2):\n",
    "    g = torch.Generator().manual_seed(42)\n",
    "    model = modules.GPT2(\n",
    "        vocab_size, embed_dim, context_len, num_heads, use_flash_attention=True\n",
    "    )\n",
    "    model.to(device)\n",
    "    model = torch.compile(model)\n",
    "    labels = [\"flash_attn\", \"torch.compile\"]\n",
    "    if enable_tf32:\n",
    "        labels.append(\"tf32\")\n",
    "    if enable_bf16_amp:\n",
    "        labels.append(\"bf16\")\n",
    "    if len(labels) == 2:\n",
    "        labels.append(\"fp32\")\n",
    "    label = \", \".join(labels)\n",
    "    pipeline.train_gpt2(\n",
    "        model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        num_epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        generator=g,\n",
    "        enable_tf32=enable_tf32,\n",
    "        enable_bf16_amp=enable_bf16_amp,\n",
    "        label=label,\n",
    "        logging_interval=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TODO: Dig into why flash attention + torch.compile is only a bit faster than just torch.compile.\n",
    "Notably, the tokens processing rate is worse for TF32 and backward passes are slower for every configuration.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
